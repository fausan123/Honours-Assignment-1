{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Honours-Assignment1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fausan Asharaf**  <br />\n",
        "S5-CSE <br /> Roll No: 31 <br /> TVE19CS031"
      ],
      "metadata": {
        "id": "iNqZVieawtho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data and splitting it into train and test sets"
      ],
      "metadata": {
        "id": "EGH-N7DmheSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# x_train: (60000, 28, 28)\n",
        "# y_train: (10000, 28, 28)\n",
        "\n",
        "x_train, x_test = x_train / 255, x_test / 255"
      ],
      "metadata": {
        "id": "pZ0xBZXJLsW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49e2c22-3341-41c2-df6b-28f72d653dc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "Here the layers are: 1 input layer having 784 neurons, 1 hidden layer having 32 units and 1 output layers having 10 units (10 classes). The count of total parameters is 25450 which is much less than the training size of 60000.\n",
        "Hidden layer uses 'ReLU' activation function and output layers uses softmax.\n",
        "Model is trained for 5 epochs."
      ],
      "metadata": {
        "id": "sJHOE8D4i0AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "model1.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "model1.summary()\n",
        "\n",
        "print(\"Training...\")\n",
        "model1.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "print(\"Testing...\")\n",
        "model1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SFmt31VS9KR",
        "outputId": "e858ba5b-a528-455a-8258-5dbc53fb8940"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3575 - accuracy: 0.8982\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1762 - accuracy: 0.9485\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1386 - accuracy: 0.9589\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1169 - accuracy: 0.9655\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1036 - accuracy: 0.9691\n",
            "Testing...\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1163 - accuracy: 0.9627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11630820482969284, 0.9627000093460083]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1:\n",
        "\n",
        "*   Number of epochs = 5 \n",
        "*   Training Accuracy = 0.9691\n",
        "*   Test Accuray = 0.9627\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t7x6c8J-h2Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2\n",
        "\n",
        "Layers are: 1 input layer having 784 neurons, 2 hidden layers, one having 64 units and other having 32 units and 1 output layers having 10 units (10 classes).The count of total parameters is 52650 which is really close to the training size of 60000, so there is high chance that this model will suffer from overfitting.\n",
        "Hidden layers uses 'ReLU' activation function and output layers uses softmax.\n",
        "Model is trained for 20 epochs."
      ],
      "metadata": {
        "id": "rsGqQVpmlyqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "model2.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "model2.summary()\n",
        "\n",
        "print(\"Training...\")\n",
        "model1.fit(x_train, y_train, epochs=20)\n",
        "\n",
        "print(\"Testing...\")\n",
        "model1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHqbOgi8Uk9R",
        "outputId": "9f5b61b2-8e04-4846-802b-a78b9849fd3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,650\n",
            "Trainable params: 52,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0345 - accuracy: 0.9893\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0323 - accuracy: 0.9898\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0295 - accuracy: 0.9912\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0290 - accuracy: 0.9910\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0275 - accuracy: 0.9917\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0264 - accuracy: 0.9916\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0246 - accuracy: 0.9922\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0237 - accuracy: 0.9927\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0221 - accuracy: 0.9931\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0214 - accuracy: 0.9934\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.9940\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.9939\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0179 - accuracy: 0.9947\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0180 - accuracy: 0.9946\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0174 - accuracy: 0.9947\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0159 - accuracy: 0.9953\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0154 - accuracy: 0.9952\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0142 - accuracy: 0.9960\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0141 - accuracy: 0.9959\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0134 - accuracy: 0.9961\n",
            "Testing...\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1657 - accuracy: 0.9673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16574342548847198, 0.9672999978065491]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2:\n",
        "\n",
        "*   Number of epochs = 20\n",
        "*   Training Accuracy = 0.9961\n",
        "*   Test Accuray = 0.9673\n"
      ],
      "metadata": {
        "id": "c06uryjTmiKr"
      }
    }
  ]
}